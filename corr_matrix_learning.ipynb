{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Change these to the subjects folder / personal paths\n",
    "PWD = \"/home/dario/repos/malis-project-autism/data/brain_data_processed/output/cpac_singul_pipeline\"\n",
    "ABIDEII_CSV_PATH = \"/home/dario/repos/malis-project-autism/data/ABIDEII_Composite_Phenotypic.csv\"\n",
    "FMRI_DIR = \"func\" # change with \"rest_1\" as needed\n",
    "\n",
    "### Reading the correlation matrixes from files ###\n",
    "\n",
    "subj_dirs = [f\"{d}/{FMRI_DIR}\" for d in os.listdir(PWD)]\n",
    "matrixes, sub_ids = list(), list()\n",
    "for sub in subj_dirs:\n",
    "    file = [f for f in os.listdir(PWD+\"/\"+sub) if f.find(\"CC200_desc-ndmg-1_correlations.csv\") > -1]\n",
    "    if file:\n",
    "        with open(f\"{PWD}/{sub}/{file[0]}\", 'r') as f:\n",
    "            corr_file = f.read().split('\\n')[:-1]\n",
    "        header = corr_file[0].split(',')\n",
    "        matrix = [[float(x) for x in row.split(',')] for row in corr_file[1:]]\n",
    "        \n",
    "        # Excluding 0.0 value matrixes\n",
    "        if not all(map(lambda x : x == 0.0, matrix[0])):\n",
    "            matrixes.append(matrix)\n",
    "            sub_ids.append(int(sub.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "### Extracting the features and labels ###\n",
    "\n",
    "pheno_df = pd.read_csv(ABIDEII_CSV_PATH)\n",
    "id_labels = dict(zip(pheno_df.SUB_ID, pheno_df.DX_GROUP))\n",
    "id_sex = dict(zip(pheno_df.SUB_ID, pheno_df.SEX))\n",
    "\n",
    "X = list()\n",
    "for matr in matrixes:\n",
    "    x = list()\n",
    "    for i in range(len(matr)):\n",
    "        for j in range(len(matr[i])):\n",
    "            if j < i:\n",
    "                x.append(matr[i][j])\n",
    "    X.append(x)\n",
    "\n",
    "y = [id_labels[sub] for sub in sub_ids]\n",
    "\n",
    "sexes = [id_labels[sub] for sub in sub_ids]\n",
    "# males_X = [x for x, sex in zip(X, sexes) if sex == 1]\n",
    "# males_y = [label for label, sex in zip(y, sexes) if sex == 1]\n",
    "# females_X = [x for x, sex in zip(X, sexes) if sex == 2]\n",
    "# females_y = [label for label, sex in zip(y, sexes) if sex == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Accuracy score (most frequent) : 0.4567901234567901\n",
      "Dummy Accuracy score (stratified) : 0.49382716049382713\n"
     ]
    }
   ],
   "source": [
    "### Implementing a dummy classification as baseline ###\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "dummy_classifier_mf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier_mf.fit(X_train, y_train)\n",
    "\n",
    "y_hat = dummy_classifier_mf.predict(X_test)\n",
    "acc_mf = accuracy_score(y_test, y_hat)\n",
    "print(f\"Dummy Accuracy score (most frequent) : {acc_mf}\")\n",
    "\n",
    "dummy_classifier_strat = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_classifier_strat.fit(X_train, y_train)\n",
    "\n",
    "y_hat = dummy_classifier_strat.predict(X_test)\n",
    "acc_strat = accuracy_score(y_test, y_hat)\n",
    "print(f\"Dummy Accuracy score (stratified) : {acc_strat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Test Females: 38\tOuter Test Males: 43\n",
      "### Logistic Regression results ###\n",
      "Training accuracy of each fold - [0.9375, 0.9270833333333334, 0.9375, 0.9322916666666666, 0.921875]\n",
      "Avg train accuracy : 0.93125\n",
      "Testing accuracy of each fold - [0.4583333333333333, 0.5833333333333334, 0.4791666666666667, 0.5833333333333334, 0.5833333333333334]\n",
      "Avg testing accuracy : 0.5375000000000001\n",
      "\n",
      "### SVC results ###\n",
      "Training accuracy of each fold - [0.6041666666666666, 0.6041666666666666, 0.59375, 0.65625, 0.6822916666666666]\n",
      "Avg train accuracy : 0.6281249999999999\n",
      "Testing accuracy of each fold - [0.4791666666666667, 0.5625, 0.5416666666666666, 0.5833333333333334, 0.5625]\n",
      "Avg testing accuracy : 0.5458333333333334\n",
      "\n",
      "### Testing on Female subjects ###\n",
      "Testing score on Female subjects (Logistic Regression): 0.5\n",
      "Testing score on Female subjects (SVC): 0.34210526315789475\n",
      "\n",
      "### Testing on Male subjects ###\n",
      "Testing score on Male subjects (Logistic Regression): 0.6744186046511628\n",
      "Testing score on Male subjects (SVC): 0.5581395348837209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Implementing cross validation ###\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "train_accs_logreg, test_accs_logreg = [], []\n",
    "train_accs_svc, test_accs_svc = [], []\n",
    "logreg_models, svc_models = [], []\n",
    "X_train_out, X_test_out, y_train_out, y_test_out = train_test_split(X, y, test_size=0.25)\n",
    "X_train_out = np.array(X_train_out)\n",
    "X_test_out = np.array(X_test_out)\n",
    "y_train_out = np.array(y_train_out)\n",
    "y_test_out = np.array(y_test_out)\n",
    "\n",
    "males_X = [x for x, sex in zip(X_test_out, sexes) if sex == 1]\n",
    "males_y = [label for label, sex in zip(y_test_out, sexes) if sex == 1]\n",
    "females_X = [x for x, sex in zip(X_test_out, sexes) if sex == 2]\n",
    "females_y = [label for label, sex in zip(y_test_out, sexes) if sex == 2]\n",
    "print(f\"Outer Test Females: {len(females_X)}\\tOuter Test Males: {len(males_X)}\")\n",
    "\n",
    "for train_index , test_index in kf.split(X_train_out):\n",
    "    # Data splitting\n",
    "    # X_train , X_test = np.take(X_train_out,train_index,axis=0), np.take(X_test_out,test_index,axis=0)\n",
    "    # y_train , y_test = np.take(y_train_out,train_index), np.take(y_test_out,test_index)\n",
    "    X_train , X_test = X_train_out[train_index, :], X_train_out[test_index, :] \n",
    "    y_train , y_test = y_train_out[train_index], y_train_out[test_index] \n",
    "\n",
    "    # Training on Logistic Regression\n",
    "    logreg_model = LogisticRegression(solver='liblinear', penalty='l1', C=0.5)\n",
    "    logreg_model.fit(X_train,y_train)\n",
    "    pred_values_train = logreg_model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, pred_values_train)\n",
    "    train_accs_logreg.append(acc_train)\n",
    "\n",
    "    # Testing on Logistic Regression\n",
    "    pred_values_test = logreg_model.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, pred_values_test)\n",
    "    test_accs_logreg.append(acc_test)\n",
    "\n",
    "\n",
    "    # Training on Support Vector Classifier\n",
    "    svc_model = SVC(kernel=\"linear\", C=0.001)\n",
    "    svc_model.fit(X_train, y_train)\n",
    "    acc_train = svc_model.score(X_train, y_train)\n",
    "    train_accs_svc.append(acc_train)\n",
    "\n",
    "    # Testing on Support Vector Classifier\n",
    "    acc_test = svc_model.score(X_test, y_test)\n",
    "    test_accs_svc.append(acc_test)\n",
    "\n",
    "\n",
    "    # Saving each fold's model\n",
    "    logreg_models.append(logreg_model)\n",
    "    svc_models.append(svc_model)\n",
    "\n",
    "\n",
    "\n",
    "print(\"### Logistic Regression results ###\")\n",
    "print(f\"Training accuracy of each fold - {train_accs_logreg}\")\n",
    "print(f\"Avg train accuracy : {sum(train_accs_logreg)/k}\")\n",
    "print(f\"Testing accuracy of each fold - {test_accs_logreg}\")\n",
    "print(f\"Avg testing accuracy : {sum(test_accs_logreg)/k}\")\n",
    "print()\n",
    "\n",
    "print(\"### SVC results ###\")\n",
    "print(f\"Training accuracy of each fold - {train_accs_svc}\")\n",
    "print(f\"Avg train accuracy : {sum(train_accs_svc)/k}\")\n",
    "print(f\"Testing accuracy of each fold - {test_accs_svc}\")\n",
    "print(f\"Avg testing accuracy : {sum(test_accs_svc)/k}\")\n",
    "print()\n",
    "\n",
    "best_logreg = logreg_models[np.argmax(test_accs_logreg)]\n",
    "best_svc = svc_models[np.argmax(test_accs_svc)]\n",
    "\n",
    "print(\"### Testing on Female subjects ###\")\n",
    "female_score = best_logreg.score(females_X, females_y)\n",
    "print(f\"Testing score on Female subjects (Logistic Regression): {female_score}\")\n",
    "female_score = best_svc.score(females_X, females_y)\n",
    "print(f\"Testing score on Female subjects (SVC): {female_score}\")\n",
    "print()\n",
    "\n",
    "print(\"### Testing on Male subjects ###\")\n",
    "male_score = best_logreg.score(males_X, males_y)\n",
    "print(f\"Testing score on Male subjects (Logistic Regression): {male_score}\")\n",
    "male_score = best_svc.score(males_X, males_y)\n",
    "print(f\"Testing score on Male subjects (SVC): {male_score}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "model_lr_nested = LogisticRegression(solver=\"liblinear\", penalty=\"l1\")\n",
    "model_svm_nested = SVC(kernel=\"linear\")\n",
    "\n",
    "p_grid = {\"C\": [0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 100]}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10)\n",
    "clf_lr = GridSearchCV(estimator=model_lr_nested, param_grid=p_grid, cv=cv)\n",
    "clf_svm = GridSearchCV(estimator=model_svm_nested, param_grid=p_grid, cv=cv)\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "performance_train_lr = []\n",
    "performance_test_lr = []\n",
    "performance_train_svm = []\n",
    "performance_test_svm = []\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    X_train, X_test = X[train_idx, :], X[test_idx, :]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    clf_lr.fit(X_train, y_train)\n",
    "    preds_train_nested = clf_lr.predict(X_train)\n",
    "    performance_train_lr.append(accuracy_score(y_train, preds_train_nested))\n",
    "    preds_test_nested = clf_lr.predict(X_test)\n",
    "    performance_test_lr.append(accuracy_score(y_test, preds_test_nested))\n",
    "\n",
    "    clf_svm.fit(X_train, y_train)\n",
    "    preds_train_nested = clf_svm.predict(X_train)\n",
    "    performance_train_svm.append(accuracy_score(y_train, preds_train_nested))\n",
    "    preds_test_nested = clf_svm.predict(X_test)\n",
    "    performance_test_svm.append(accuracy_score(y_test, preds_test_nested))\n",
    "\n",
    "observed_acc_train_lr = np.mean(performance_train_lr)\n",
    "observed_acc_test_lr = np.mean(performance_test_lr)\n",
    "print(\"Mean lr training accuracy across folds = %.3f\" % observed_acc_train_lr)\n",
    "print(\"Mean lr testing accuracy across folds = %.3f\" % observed_acc_test_lr)\n",
    "observed_acc_train_svm = np.mean(performance_train_svm)\n",
    "observed_acc_test_svm = np.mean(performance_test_svm)\n",
    "print(\"Mean svm training accuracy across folds = %.3f\" % observed_acc_train_svm)\n",
    "print(\"Mean svm testing accuracy across folds = %.3f\" % observed_acc_test_svm)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f22182d3dea5b4a9c0368799fcb627b8750a7cf25466b8551d2cf611112acc39"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}